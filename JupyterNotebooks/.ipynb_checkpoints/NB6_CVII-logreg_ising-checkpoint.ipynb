{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: Phases of the Ising Model with Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goal\n",
    "The goal of this notebook is to show how one can employ Logistic Regression to classify the states of the 2D Ising model according to their phase. We will discuss overfitting, regularization, and learn how to use the scikit-learn library. We will also examine the role of the optimizer in making predictions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The energy function of the classical Ising model is given by\n",
    "\n",
    "$$ H = -J\\sum_{\\langle ij\\rangle}S_{i}S_j,\\qquad \\qquad S_j\\in\\{\\pm 1\\} $$\n",
    "\n",
    "where the lattice site indices $i,j$ run over all nearest neighbors of a 2D square lattice, and $J$ is some arbitrary interaction energy scale. We adopt periodic boundary conditions. Onsager proved that this model undergoes a thermal phase transition in the thermodynamic limit from an ordered ferromagnet with all spins aligned to a disordered phase at the critical temperature $T_c/J=2/\\log(1+\\sqrt{2})\\approx 2.26$. For any finite system size, this critical point is expanded to a critical region around $T_c$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting question to ask is whether one can train a statistical model to distinguish between the two phases of the Ising model. If successful, this can be used to locate the position of the critical point in more complicated models where an exact analytical solution has so far remained elusive. \n",
    "\n",
    "In other words, given an Ising state, we would like to classify whether it belongs to the ordered or the disordered phase, without any additional information other than the spin configuration itself. This categorical machine learning problem is well suited for logistic regression. Notice that, for the purposes of applying logistic regression, the 2D spin state of the Ising model will be flattened out to a 1D array, so it will not be easy to learn information about the structure of the contiguous ordered 2D domains [see figure below]. Such information can be incorporated using other methods such as multi-layer deep convolutional neural networks (CNNs), see Secs. IX, X and XI of the review and the corresponding notebooks.\n",
    "\n",
    "## The 2D Ising Dataset\n",
    "\n",
    "To this end, we consider the 2D Ising model on a $40\\times 40$ square lattice, and use Monte-Carlo (MC) sampling to prepare $10^4$ states at every fixed temperature $T$ out of a pre-defined set $T\\in[0.25,0.5,\\cdots,4.0]$. Using Onsager's criterion, we can assign a label to each state according to its phase: $0$ if the state is disordered, and $1$ if it is ordered. Our goal is to predict the phase of a sample given the spin configuration.\n",
    "\n",
    "It is well-known that, near the critical temperature $T_c$, the ferromagnetic correlation length diverges which, among other things, leads to a critical slowing down of the MC algorithm. Therefore, we expect identifying the phases to be harder in the critical region. With this in mind, consider the following three types of states: ordered ($T/J<2.0$), critical ($2.0\\leq T/J\\leq 2.5)$ and disordered ($T/J>2.5$). We use both ordered and disordered states to train the logistic regressor and once the supervised training procedure is complete, we evaluate the performance of our classification model on unseen ordered, disordered and critical states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed() # shuffle random seed generator\n",
    "\n",
    "# Ising model parameters\n",
    "L=40 # linear system size\n",
    "J=-1.0 # Ising interaction\n",
    "T=np.linspace(0.25,4.0,16) # set of temperatures\n",
    "T_c=2.26 # Onsager critical temperature in the TD limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Ising dataset\n",
    "We now load in the data which is hosted on Pankaj Mehta's [website](http://physics.bu.edu/~pankajm/MLnotebooks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "from urllib.request import urlopen \n",
    "\n",
    "# url to data\n",
    "url_main = 'https://physics.bu.edu/~pankajm/ML-Review-Datasets/isingMC/';\n",
    "\n",
    "######### LOAD DATA\n",
    "# The data consists of 16*10000 samples taken in T=np.arange(0.25,4.0001,0.25):\n",
    "data_file_name = \"Ising2DFM_reSample_L40_T=All.pkl\" \n",
    "# The labels are obtained from the following file:\n",
    "label_file_name = \"Ising2DFM_reSample_L40_T=All_labels.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "#DATA\n",
    "data = pickle.load(urlopen(url_main + data_file_name)) # pickle reads the file and returns the Python object (1D array, compressed bits)\n",
    "data = np.unpackbits(data).reshape(-1, 1600) # Decompress array and reshape for convenience\n",
    "data=data.astype('int')\n",
    "data[np.where(data==0)]=-1 # map 0 state to -1 (Ising variable can take values +/-1)\n",
    "\n",
    "#LABELS (convention is 1 for ordered states and 0 for disordered states)\n",
    "labels = pickle.load(urlopen(url_main + label_file_name)) # pickle reads the file and returns the Python object (here just a 1D array with the binary labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the training and the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([70000]))\n",
      "(array([0, 1]), array([10000, 20000]))\n",
      "(array([0]), array([60000]))\n",
      "X_train shape: (30000, 1600)\n",
      "Y_train shape: (30000,)\n",
      "\n",
      "30000 train samples\n",
      "30000 critical samples\n",
      "65000 test samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###### define ML parameters\n",
    "num_classes=2\n",
    "train_to_test_ratio=0.5 # training samples\n",
    "\n",
    "# divide data into ordered, critical and disordered\n",
    "X_ordered=data[:70000,:]\n",
    "Y_ordered=labels[:70000]\n",
    "\n",
    "print(np.unique(Y_ordered, return_counts=True))\n",
    "\n",
    "# samples in the critical region 2.0 < T/J < 2.5\n",
    "X_critical=data[70000:100000,:]\n",
    "Y_critical=labels[70000:100000]\n",
    "\n",
    "print(np.unique(Y_critical, return_counts=True))\n",
    "\n",
    "X_disordered=data[100000:,:]\n",
    "Y_disordered=labels[100000:]\n",
    "\n",
    "print(np.unique(Y_disordered, return_counts=True))\n",
    "\n",
    "#del data,labels\n",
    "\n",
    "# define training and test data sets\n",
    "X=np.concatenate((X_ordered,X_disordered))\n",
    "Y=np.concatenate((Y_ordered,Y_disordered))\n",
    "\n",
    "crRegionOnly=True # training/testing samples from critical region only or outside the critical region\n",
    "\n",
    "def prepareTrainTestSamples(X, Y, X_critical, Y_critical, train_to_test_ratio, crRegionOnly=False):\n",
    "    '''Prepare training and testing datasets for the classifiers.\n",
    "    If crRegionOnly=True  : Only 30000 samples in the critical region will be considered.\n",
    "    If crRegionOnly=False : Samples outside of the critical region will be considered.\n",
    "    Returns the train/test spin configurations and the corresponding labels.\n",
    "    '''\n",
    "    if not crRegionOnly:\n",
    "        X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=train_to_test_ratio,test_size=1.0-train_to_test_ratio)\n",
    "    else:\n",
    "        # Prepare training samples only from critical region where 2.0 < T/J < 2.5\n",
    "        X_train, Y_train = X_critical, Y_critical\n",
    "        _,X_test,_,Y_test=train_test_split(X,Y,train_size=train_to_test_ratio,test_size=1.0-train_to_test_ratio)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = prepareTrainTestSamples(X, Y, X_critical, Y_critical, \n",
    "                                                           train_to_test_ratio, crRegionOnly)\n",
    "        \n",
    "# full data set\n",
    "X=np.concatenate((X_critical,X))\n",
    "Y=np.concatenate((Y_critical,Y))\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_critical.shape[0], 'critical samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### plot a few Ising states\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# set colourbar map\n",
    "cmap_args=dict(cmap='plasma_r')\n",
    "\n",
    "# plot states\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "axarr[0].imshow(X_ordered[20001].reshape(L,L),**cmap_args)\n",
    "axarr[0].set_title('$\\\\mathrm{ordered\\\\ phase}$',fontsize=16)\n",
    "axarr[0].tick_params(labelsize=16)\n",
    "\n",
    "axarr[1].imshow(X_critical[10001].reshape(L,L),**cmap_args)\n",
    "axarr[1].set_title('$\\\\mathrm{critical\\\\ region}$',fontsize=16)\n",
    "axarr[1].tick_params(labelsize=16)\n",
    "\n",
    "im=axarr[2].imshow(X_disordered[50001].reshape(L,L),**cmap_args)\n",
    "axarr[2].set_title('$\\\\mathrm{disordered\\\\ phase}$',fontsize=16)\n",
    "axarr[2].tick_params(labelsize=16)\n",
    "\n",
    "fig.subplots_adjust(right=2.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function, optimizers, regularizers, and performance metrics\n",
    "\n",
    "In Sec. VII of the review, we have shown that the cross-entropy is a natural cost function used for training a logistic regressor. As we already mentioned, minimizing it requires the use of numerical toolboxes. Here, we compare the performance of two different optimization routines: a `liblinear` [the default one for scikit's logistic regression], and stochastic gradient descent (SGD) [see Sec. IV of the review for more details].\n",
    "\n",
    "It is important to note that all these methods have built-in regularizers. Indeed, we did not discuss the role of the regularisor explicitly in the context of Logistic Regression extensively, yet this concept is crucial in order to prevent overfitting, and we encourage the interested reader to play with the different regularization types and regularization strengths and compare model performances. \n",
    "\n",
    "Below, we define the accuracy of a classification model on a given data set as the percentage of correctly classified data points. Comparing the accuracy on the training and test data, we obtain a good estimate of the degree of overfitting. Well-trained models do not overfit the data, which is reflected in an almost equal performance on the training and test data sets [recall that the test set consists of samples which the model has not been trained on]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the cell below (this may take several minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: train, test, critical\n",
      "liblin: 0.7413, 0.6585, 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alpakpinar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.6683, 0.6057, 0.6370\n",
      "finished computing 1/11 iterations\n",
      "accuracy: train, test, critical\n",
      "liblin: 0.7413, 0.6585, 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alpakpinar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.6871, 0.6199, 0.6535\n",
      "finished computing 2/11 iterations\n",
      "accuracy: train, test, critical\n",
      "liblin: 0.7413, 0.6585, 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alpakpinar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.7349, 0.6585, 0.6967\n",
      "finished computing 3/11 iterations\n",
      "accuracy: train, test, critical\n",
      "liblin: 0.7413, 0.6585, 0.6999\n",
      "SGD: 0.7352, 0.6665, 0.7009\n",
      "finished computing 4/11 iterations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-79c3154a8c1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# fit training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# check accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    922\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### apply logistic regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# define regularisation parameter\n",
    "lmbdas=np.logspace(-5,5,11)\n",
    "\n",
    "# preallocate data\n",
    "train_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "test_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "critical_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "\n",
    "train_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "test_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "critical_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "\n",
    "# loop over regularisation strength\n",
    "for i,lmbda in enumerate(lmbdas):\n",
    "\n",
    "    # define logistic regressor\n",
    "    logreg=linear_model.LogisticRegression(penalty='l2',C=1.0/lmbda,random_state=1,verbose=0,max_iter=1E3,tol=1E-5,\n",
    "                                           solver='liblinear')\n",
    "\n",
    "    # fit training data\n",
    "    logreg.fit(X_train, Y_train)\n",
    "\n",
    "    # check accuracy\n",
    "    train_accuracy[i]=logreg.score(X_train,Y_train)\n",
    "    test_accuracy[i]=logreg.score(X_test,Y_test)\n",
    "    critical_accuracy[i]=logreg.score(X_critical,Y_critical)\n",
    "    \n",
    "    print('accuracy: train, test, critical')\n",
    "    print('liblin: %0.4f, %0.4f, %0.4f' %(train_accuracy[i],test_accuracy[i],critical_accuracy[i]) )\n",
    "\n",
    "    # define SGD-based logistic regression\n",
    "    logreg_SGD = linear_model.SGDClassifier(loss='log', penalty='l2', alpha=lmbda, max_iter=100, \n",
    "                                           shuffle=True, random_state=1, learning_rate='optimal')\n",
    "\n",
    "    # fit training data\n",
    "    logreg_SGD.fit(X_train,Y_train)\n",
    "\n",
    "    # check accuracy\n",
    "    train_accuracy_SGD[i]=logreg_SGD.score(X_train,Y_train)\n",
    "    test_accuracy_SGD[i]=logreg_SGD.score(X_test,Y_test)\n",
    "    critical_accuracy_SGD[i]=logreg_SGD.score(X_critical,Y_critical)\n",
    "    \n",
    "    print('SGD: %0.4f, %0.4f, %0.4f' %(train_accuracy_SGD[i],test_accuracy_SGD[i],critical_accuracy_SGD[i]) )\n",
    "\n",
    "    print('finished computing %i/11 iterations' %(i+1))\n",
    "\n",
    "# plot accuracy against regularisation strength\n",
    "plt.semilogx(lmbdas,train_accuracy,'*-b',label='newton-cg train')\n",
    "plt.semilogx(lmbdas,test_accuracy,'*-r',label='newton-cg test')\n",
    "plt.semilogx(lmbdas,critical_accuracy,'*-g',label='newton-cg critical')\n",
    "\n",
    "plt.semilogx(lmbdas,train_accuracy_SGD,'*--b',label='SGD train')\n",
    "plt.semilogx(lmbdas,test_accuracy_SGD,'*--r',label='SGD test')\n",
    "plt.semilogx(lmbdas,critical_accuracy_SGD,'*--g',label='SGD critical')\n",
    "\n",
    "plt.xlabel('$\\\\lambda$')\n",
    "plt.ylabel('$\\\\mathrm{accuracy}$')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('plots6/performance_solver_newton-cg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "********************\n",
      "In the training dataset:\n",
      "Number of unordered states: 10000 (0.33)\n",
      "Number of ordered states: 20000 (0.67)\n",
      "********************\n",
      "Training set size: 30000\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alpakpinar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.6692, 0.6844\n",
      "finished computing 1/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alpakpinar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.6722, 0.6762\n",
      "finished computing 2/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6278\n",
      "SGD: 0.7204, 0.6403\n",
      "finished computing 3/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6278\n",
      "SGD: 0.7126, 0.6119\n",
      "finished computing 4/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6278\n",
      "SGD: 0.6764, 0.5502\n",
      "finished computing 5/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6277\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 6/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7173, 0.6272\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 7/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7167, 0.6224\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 8/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7067, 0.5955\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 9/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.6862, 0.5584\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 10/11 iterations\n",
      "accuracy: train, test\n",
      "liblinear: 0.7029, 0.5707\n",
      "SGD: 0.6667, 0.5376\n",
      "finished computing 11/11 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### apply logistic regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# define regularisation parameter\n",
    "lmbdas=np.logspace(-5,5,11)\n",
    "\n",
    "def fitAndPlot(lmbdas, X_train, X_test, Y_train, Y_test, crRegionOnly=False, solver='liblinear', penalty='l2'):\n",
    "    '''Train the two classifier models for different values of lambda \n",
    "    and plot the performance curves as a function of lambda.\n",
    "    \n",
    "    If crRegionOnly=False, the performance on critical dataset will also be considered \n",
    "    seperately for performance of each classifier, with two other training/testing sets.\n",
    "    \n",
    "    If crRegionOnly=True, training dataset will be the data generated at the critical temperature region.\n",
    "    \n",
    "    Solver algorithm and penalty (regularization) can be specified.\n",
    "    \n",
    "    Doesn't return anything.\n",
    "    '''\n",
    "    \n",
    "    print('Training set size: %d' % X_train.shape[0])\n",
    "    \n",
    "    # preallocate data\n",
    "    train_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "    test_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "    critical_accuracy=np.zeros(lmbdas.shape,np.float64)\n",
    "\n",
    "    train_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "    test_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "    critical_accuracy_SGD=np.zeros(lmbdas.shape,np.float64)\n",
    "   \n",
    "    # loop over regularisation strength\n",
    "    for i,lmbda in enumerate(lmbdas):\n",
    "\n",
    "        # define logistic regressor\n",
    "        logreg=linear_model.LogisticRegression(penalty=penalty,C=1.0/lmbda,random_state=1,verbose=0,max_iter=1E3,tol=1E-5,\n",
    "                                               solver=solver)\n",
    "\n",
    "        # fit training data\n",
    "        logreg.fit(X_train, Y_train)\n",
    "\n",
    "        # check accuracy\n",
    "        train_accuracy[i]=logreg.score(X_train,Y_train)\n",
    "        test_accuracy[i]=logreg.score(X_test,Y_test)\n",
    "        if not crRegionOnly:\n",
    "            critical_accuracy[i]=logreg.score(X_critical,Y_critical)\n",
    "            print('accuracy: train, test, critical')\n",
    "            print('%s: %0.4f, %0.4f, %0.4f' %(solver,train_accuracy[i],test_accuracy[i],critical_accuracy[i]))\n",
    "        else:\n",
    "            print('accuracy: train, test')\n",
    "            print('%s: %0.4f, %0.4f' % (solver,train_accuracy[i],test_accuracy[i]))\n",
    "        \n",
    "        # define SGD-based logistic regression\n",
    "        logreg_SGD = linear_model.SGDClassifier(loss='log', penalty=penalty, alpha=lmbda, max_iter=100, \n",
    "                                               shuffle=True, random_state=1, learning_rate='optimal')\n",
    "\n",
    "        # fit training data\n",
    "        logreg_SGD.fit(X_train,Y_train)\n",
    "\n",
    "        # check accuracy\n",
    "        train_accuracy_SGD[i]=logreg_SGD.score(X_train,Y_train)\n",
    "        test_accuracy_SGD[i]=logreg_SGD.score(X_test,Y_test)\n",
    "        if not crRegionOnly:\n",
    "            critical_accuracy_SGD[i]=logreg_SGD.score(X_critical,Y_critical)\n",
    "            print('SGD: %0.4f, %0.4f, %0.4f' %(train_accuracy_SGD[i],test_accuracy_SGD[i],critical_accuracy_SGD[i]) )\n",
    "        else:\n",
    "            print('SGD: %0.4f, %0.4f' %(train_accuracy_SGD[i],test_accuracy_SGD[i]))\n",
    "\n",
    "        print('finished computing %i/11 iterations' %(i+1))\n",
    "\n",
    "    # plot accuracy against regularisation strength\n",
    "    plt.semilogx(lmbdas,train_accuracy,'*-b',label='%s train' % solver)\n",
    "    plt.semilogx(lmbdas,test_accuracy,'*-r',label='%s test' % solver)\n",
    "    if not crRegionOnly:\n",
    "        plt.semilogx(lmbdas,critical_accuracy,'*-g',label='%s critical' % solver)\n",
    "\n",
    "    plt.semilogx(lmbdas,train_accuracy_SGD,'*--b',label='SGD train')\n",
    "    plt.semilogx(lmbdas,test_accuracy_SGD,'*--r',label='SGD test')\n",
    "    if not crRegionOnly:\n",
    "        plt.semilogx(lmbdas,critical_accuracy_SGD,'*--g',label='SGD critical')\n",
    "\n",
    "    plt.xlabel('$\\\\lambda$')\n",
    "    plt.ylabel('$\\\\mathrm{accuracy}$')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('plots6/performance_solver_{SOLVER}_iscr={ISCR}.png'.format(SOLVER=solver, ISCR=crRegionOnly))\n",
    "    plt.show()\n",
    "    \n",
    "#################\n",
    "# Do the training & get the results\n",
    "#################\n",
    "\n",
    "numTrainStates = X_train.shape[0]\n",
    "\n",
    "crRegionOnly = (numTrainStates == 30000)\n",
    "numUnorderedStates = np.unique(Y_train, return_counts=True)[1][0]\n",
    "numOrderedStates = np.unique(Y_train, return_counts=True)[1][1]\n",
    "ratioUnorderedStates = float(numUnorderedStates)/numTrainStates\n",
    "ratioOrderedStates = float(numOrderedStates)/numTrainStates\n",
    "\n",
    "print('*'*20)\n",
    "print('In the training dataset:')\n",
    "print('Number of unordered states: %d (%.2f)' % (numUnorderedStates, ratioUnorderedStates))\n",
    "print('Number of ordered states: %d (%.2f)' % (numOrderedStates, ratioOrderedStates))\n",
    "print('*'*20)\n",
    "\n",
    "\n",
    "fitAndPlot(lmbdas, X_train, X_test, Y_train, Y_test, crRegionOnly=crRegionOnly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interpreting the results\n",
    "\n",
    "The first thing we can read off the figure above is the relative degree of overfitting. This information is contained in the difference in accuracy of our model on the training (blue) and test (red) datasets. Notice that the accuracy difference between test and training sets is significant but not unreasonable, within $10\\%$. Interestingly, which optimizer performs better depends on the value of the regularization strength. Moreover, similar to the Linear Regression examples, we find that there exists a sweet spot for the regularization strength $\\lambda$ that results in optimal performance of the logistic regressor, at about $\\lambda\\sim 10^{-1}$.\n",
    "\n",
    "Due to the physics of the Ising model close to criticality, we expect that predicting the phase of a sample will become much more difficult close to the critical point. We can visually see this by looking at the states in the critical region, (see Fig. above and plot other examples). Notice that it is no longer easy even for a trained human eye to distinguish between the ferromagnetic and the disordered phases close to $T_c$. \n",
    "\n",
    "It is an interesting exercise to compare the training and test accuracies in the ordered and disordered phases to the accuracy of the model near the critical point (i.e. critical states). Recall that the model is not trained on critical states. Notice that the accuracy is about $10\\%$ smaller for the critical states (green curves). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: ###  \n",
    "<ul>\n",
    "<li> Change the regularization to $L^1$, or $L^1+L^2$ (i.e. elastic net, see Notebook 2 for more details), and study the performance of the model.\n",
    "\n",
    "<li> Try out different solvers supported by `LogisticRegression()`, [see online scikit documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). How do they compare to `liblinear` and `SGD`?\n",
    "\n",
    "<li> One can expect the regressor to be maximally confused exactly at the critical point. Take the data states for the closest temperature, i.e. $T/J=2.5$, and check the performance of the model. Do we get an accuracy of about $50\\%$? Does this depend on the proportion of ordered to disordered states in the training set?\n",
    "\n",
    "<li> Take the regressor trained on the square lattice Ising model, and try to predict the phases on a different lattice geometry (e.g. triangular or honeycomb). What accuracy do you obtain? Can you roughly locate the critical point in this new model? Note that this requires you to generate your own dataset using Monte-Carlo sampling.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to Exercises\n",
    "\n",
    "- Running both SGDClassifier and LogisticRegression training models with $L^2$ regularization, we get the following performances as a function of the regularization parameter, $\\lambda$:\n",
    "\n",
    "<img src=\"plots6/performance_L2reg.png\"/>\n",
    "\n",
    "Looking at the performance curves for each model, we observe that in general, liblinear routine (LogisticRegression) has a better performance for all three data categories. Only at intermediate values of $\\lambda$, the performance of SGDClassifier and LogisticRegression are comparable. In a specific region where $10^{-2} < \\lambda < 1$, we also observe that SGDClassifier has a higher performance compared to liblinear routine while classifying the samples in critical region. But as $\\lambda$ grows a little bit, this performance drops in a very fast manner.\n",
    "\n",
    "Changing the penalty from $L^2$ to $L^1$, we get the following performances as a function of $\\lambda$: \n",
    "\n",
    "<img src=\"plots6/performance_L1reg.png\"/>\n",
    "\n",
    "Here, we observe a very significant difference in the performance of LogisticRegression model: We observe that compared to the $L^2$ penalization, the performance of LogisticRegression classifier is much worse in all categories. This is indeed an expected behavior since $L^1$ penalization introduces more sparsity and hence the performance goes down more rapidly as the penalizing term, $\\lambda$ increases. For SGD training, we also observe that the performance is much worse in intermediate values of $\\lambda$, compared to the case where we used $L^2$ regularization. For any value of $\\lambda$, this model does not have an accuracy greater than $55 \\%$ on training and testing datasets. SGD classifier still has a slightly higher performance for classiyfing critical states for intermediate $\\lambda$, though.\n",
    "\n",
    "If we run the two models with elastic net penalty instead (using an l1_ratio of 0.15 for both), we get the following performances: (NOTE: for elasticnet training, saga solver is used in LogisticRegression model)\n",
    "\n",
    "<img src=\"plots6/performance_elasticnet.png\"/>\n",
    "\n",
    "From this figure, one can again observe the sharp reduction in performance for larger values of $\\lambda$. However, this reduction is not as sharp as the reduction where pure $L^1$ regularization is used. Here, again the performance of SGD classifier is overall worse, compared with the case with only $L^2$ regularization.\n",
    "\n",
    "In summary, changing the regularization didn't affect the performances of both classifiers at the very low end of $\\lambda$ spectrum. For the larger end of the spectrum, it greatly reduced the performance of LogisticRegression model. This is expected for the Ising problem because with the introduction of $L^1$ regularization, more sparsity and more suppression of specific weights are introduced. However, in the Ising problem, nearly all weights are of equal importance, therefore suppresion of a subset of the weights at higher $\\lambda$ leads to poor performance. Introduction of $L^1$ regularization also reduced the performance of SGD classifier for intermediate values of $\\lambda$, for the classification of training and testing datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running LogisticRegression classifier with saga classifier instead of liblinear, with both LogisticRegression and SGD classifiers having $L^2$ regularization, we get the following performances as a function of $\\lambda$ (plotted on the left side):\n",
    "\n",
    "<img src=\"plots6/performance_solver_saga.png\" style=\"float: left;\"/> \n",
    "<img src=\"plots6/performance_L2reg.png\" style=\"float: right;\"/>  \n",
    "<br clear='all'>\n",
    "\n",
    "Comparing this with the performance obtained using liblinear routine (plotted on the right side), we see that the performance of LogisticRegression classifier is very similar for low to intermediate $\\lambda$. For large values of $\\lambda$ however, we observe that the performance is worse in saga routine compared to liblinear. With saga, at the high end of $\\lambda$ spectrum, training and testing accuracies drop to $\\sim 55 \\%$, whereas with liblinear routine, these accuracies almost reach $70 \\%$. Other than this reduction in performance at high $\\lambda$, the two solvers seem to produce very similar results.\n",
    "\n",
    "Using Newton-Raphson Method as the solver, we get the following performance as a function of $\\lambda$ (plotted on the left side):\n",
    "\n",
    "<img src=\"plots6/performance_solver_newton-cg.png\" style=\"float: left;\"/>\n",
    "<img src=\"plots6/performance_L2reg.png\" style=\"float: right;\"/>  \n",
    "<br clear='all'>\n",
    "\n",
    "Using Newton-Raphson Method as the solver, we see almost identical results to the case where we used SAGA. Compared to the liblinear solver, the performance reduction of the LogisticRegression classifier for higher $\\lambda$ is more apparant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choosing only the data generated at the critical region, $2.0 < T/J < 2.5$, for the training dataset and testing the classifier with a mix of 65000 ordered and unordered states, we get the following performance result:\n",
    "\n",
    "<img src=\"plots6/performance_solver_liblinear_iscr=True.png\"/>\n",
    "\n",
    "Looking at this plot, we observe that the difference between the training and testing accuracies for both classifiers are at worst less than $10 \\%$. Also, with liblinear routine, we are able to reach more than $70 \\%$ accuracy in testing with $\\lambda \\sim 10^{-3}$. Therefore, for this specific training dataset, the performance of both classifiers can't be said to be worse compared to the previous cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
